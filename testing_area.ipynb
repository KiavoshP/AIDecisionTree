{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "\n",
    "def load_csv(data_file_path, class_index=-1):\n",
    "    \"\"\"Load csv data in a numpy array.\n",
    "    Args:\n",
    "        data_file_path (str): path to data file.\n",
    "        class_index (int): slice output by index.\n",
    "    Returns:\n",
    "        features, classes as numpy arrays if class_index is specified,\n",
    "            otherwise all as nump array.\n",
    "    \"\"\"\n",
    "\n",
    "    handle = open(data_file_path, 'r')\n",
    "    contents = handle.read()\n",
    "    handle.close()\n",
    "    rows = contents.split('\\n')\n",
    "    out = np.array([[float(i) for i in r.split(',')] for r in rows if r])\n",
    "\n",
    "    if(class_index == -1):\n",
    "        classes= out[:,class_index]\n",
    "        features = out[:,:class_index]\n",
    "        return features, classes\n",
    "    elif(class_index == 0):\n",
    "        classes= out[:, class_index]\n",
    "        features = out[:, 1:]\n",
    "        return features, classes\n",
    "\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class DecisionNode:\n",
    "    \"\"\"Class to represent a single node in a decision tree.\"\"\"\n",
    "\n",
    "    def __init__(self, left, right, decision_function, class_label=None):\n",
    "        \"\"\"Create a decision function to select between left and right nodes.\n",
    "        Note: In this representation 'True' values for a decision take us to\n",
    "        the left. This is arbitrary but is important for this assignment.\n",
    "        Args:\n",
    "            left (DecisionNode): left child node.\n",
    "            right (DecisionNode): right child node.\n",
    "            decision_function (func): function to decide left or right node.\n",
    "            class_label (int): label for leaf node. Default is None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.decision_function = decision_function\n",
    "        self.class_label = class_label\n",
    "\n",
    "    def _get_right(self):\n",
    "        return(self.right)\n",
    "    \n",
    "    def _get_left(self):\n",
    "        return(self.right)\n",
    "    \n",
    "    def decide(self, feature):\n",
    "        # \"\"\"Get a child node based on the decision function.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        # Args:͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        #     feature (list(int)): vector for feature.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        # Return:͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        #     Class label if a leaf node, otherwise a child node.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        # \"\"\"͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "        \"\"\"Determine recursively the class of an input array by testing a value\n",
    "           against a feature's attributes values based on the decision function.\n",
    "\n",
    "        Args:\n",
    "            feature: (numpy array(value)): input vector for sample.\n",
    "\n",
    "        Returns:\n",
    "            Class label if a leaf node, otherwise a child node.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.class_label is not None:\n",
    "            return self.class_label\n",
    "\n",
    "        elif self.decision_function(feature):\n",
    "            # print('LEFT <----')\n",
    "            return self.left.decide(feature)\n",
    "\n",
    "        else:\n",
    "            # print('----> Right')\n",
    "\n",
    "            return self.right.decide(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/vectorize.csv'\n",
    "path23 = './data/part23_data.csv'\n",
    "path_chal = './data/challenge_train.csv'\n",
    "\n",
    "class_t = True\n",
    "data = load_csv(path_chal)\n",
    "if not class_t:\n",
    "    data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.,  2., ..., 27., 28., 29.],\n",
       "        [ 0.,  2.,  3., ..., 37., 38., 39.],\n",
       "        [ 0.,  3.,  4., ..., 41., 42., 43.],\n",
       "        ...,\n",
       "        [ 0.,  3.,  4., ..., 54., 59., 65.],\n",
       "        [ 0.,  3.,  4., ..., 50., 51., 54.],\n",
       "        [ 0.,  1.,  3., ..., 51., 54., 59.]]),\n",
       " array([30., 40., 44., ..., 68., 59., 65.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Vectorization:\n",
    "    \"\"\"Vectorization preparation for Assignment 5.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def non_vectorized_loops(self, data):\n",
    "        \"\"\"Element wise array arithmetic with loops.\n",
    "        This function takes one matrix, multiplies by itself and then adds to\n",
    "        itself.\n",
    "        Args:\n",
    "            data: data to be added to array.\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "        \"\"\"\n",
    "\n",
    "        non_vectorized = np.zeros(data.shape)\n",
    "        for row in range(data.shape[0]):\n",
    "            for col in range(data.shape[1]):\n",
    "                non_vectorized[row][col] = (data[row][col] * data[row][col] +\n",
    "                                            data[row][col])\n",
    "        return non_vectorized\n",
    "\n",
    "    def vectorized_loops(self, data):\n",
    "        \"\"\"Element wise array arithmetic using vectorization.\n",
    "        This function takes one matrix, multiplies by itself and then adds to\n",
    "        itself.\n",
    "        Args:\n",
    "            data: data to be sliced and summed.\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "        \"\"\"\n",
    "\n",
    "        return (data[:][:]*data[:][:]) + data[:][:]\n",
    "\n",
    "    def non_vectorized_slice(self, data):\n",
    "        \"\"\"Find row with max sum using loops.\n",
    "        This function searches through the first 100 rows, looking for the row\n",
    "        with the max sum. (ie, add all the values in that row together).\n",
    "        Args:\n",
    "            data: data to be added to array.\n",
    "        Returns:\n",
    "            Tuple (Max row sum, index of row with max sum)\n",
    "        \"\"\"\n",
    "\n",
    "        max_sum = 0\n",
    "        max_sum_index = 0\n",
    "        for row in range(100):\n",
    "            temp_sum = 0\n",
    "            for col in range(data.shape[1]):\n",
    "                temp_sum += data[row][col]\n",
    "\n",
    "            if temp_sum > max_sum:\n",
    "                max_sum = temp_sum\n",
    "                max_sum_index = row\n",
    "\n",
    "        return max_sum, max_sum_index\n",
    "\n",
    "    def vectorized_slice(self, data):\n",
    "        \"\"\"Find row with max sum using vectorization.\n",
    "        This function searches through the first 100 rows, looking for the row\n",
    "        with the max sum. (ie, add all the values in that row together).\n",
    "        Args:\n",
    "            data: data to be sliced and summed.\n",
    "        Returns:\n",
    "            Tuple (Max row sum, index of row with max sum)\n",
    "        \"\"\"\n",
    "        sums = np.sum(data[:100][:], axis=1)\n",
    "        indx = np.where(sums == max(sums))[0][0]\n",
    "        max_sum = sums[indx]\n",
    "        return (max_sum, indx)\n",
    "\n",
    "    def non_vectorized_flatten(self, data):\n",
    "        \"\"\"Display occurrences of positive numbers using loops.\n",
    "         Flattens down data into a 1d array, then creates a dictionary of how\n",
    "         often a positive number appears in the data and displays that value.\n",
    "         ie, [(1203,3)] = integer 1203 appeared 3 times in data.\n",
    "         Args:\n",
    "            data: data to be added to array.\n",
    "        Returns:\n",
    "            List of occurrences [(integer, number of occurrences), ...]\n",
    "        \"\"\"\n",
    "\n",
    "        unique_dict = {}\n",
    "        flattened = np.hstack(data)\n",
    "        for item in range(len(flattened)):\n",
    "            if flattened[item] > 0:\n",
    "                if flattened[item] in unique_dict:\n",
    "                    unique_dict[flattened[item]] += 1\n",
    "                else:\n",
    "                    unique_dict[flattened[item]] = 1\n",
    "\n",
    "        return unique_dict.items()\n",
    "\n",
    "    def vectorized_flatten(self, data):\n",
    "        \"\"\"Display occurrences of positive numbers using vectorization.\n",
    "         Flattens down data into a 1d array, then creates a dictionary of how\n",
    "         often a positive number appears in the data and displays that value.\n",
    "         ie, [(1203,3)] = integer 1203 appeared 3 times in data.\n",
    "         Args:\n",
    "            data: data to be added to array.\n",
    "        Returns:\n",
    "            List of occurrences [(integer, number of occurrences), ...]\n",
    "        \"\"\"\n",
    "\n",
    "        return(list(Counter(np.hstack(data)[np.hstack(data) > 0]).items()))\n",
    "\n",
    "    \n",
    "    \n",
    "    def non_vectorized_glue(self, data, vector, dimension='c'):\n",
    "        \"\"\"Element wise array arithmetic with loops.\n",
    "        This function takes a multi-dimensional array and a vector, and then combines\n",
    "        both of them into a new multi-dimensional array. It must be capable of handling\n",
    "        both column and row-wise additions.\n",
    "        Args:\n",
    "            data: multi-dimensional array.\n",
    "            vector: either column or row vector\n",
    "            dimension: either c for column or r for row\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "        \"\"\"\n",
    "        if dimension == 'c' and len(vector) == data.shape[0]:\n",
    "            non_vectorized = np.ones((data.shape[0],data.shape[1]+1), dtype=float)\n",
    "            non_vectorized[:, -1] *= vector\n",
    "        elif dimension == 'r' and len(vector) == data.shape[1]:\n",
    "            non_vectorized = np.ones((data.shape[0]+1,data.shape[1]), dtype=float)\n",
    "            non_vectorized[-1, :] *= vector\n",
    "        else:\n",
    "            raise ValueError('This parameter must be either c for column or r for row')\n",
    "        for row in range(data.shape[0]):\n",
    "            for col in range(data.shape[1]):\n",
    "                non_vectorized[row, col] = data[row, col]\n",
    "        return non_vectorized\n",
    "\n",
    "    def vectorized_glue(self, data, vector, dimension='c'):\n",
    "        \"\"\"Array arithmetic without loops.\n",
    "        This function takes a multi-dimensional array and a vector, and then combines\n",
    "        both of them into a new multi-dimensional array. It must be capable of handling\n",
    "        both column and row-wise additions.\n",
    "        Args:\n",
    "            data: multi-dimensional array.\n",
    "            vector: either column or row vector\n",
    "            dimension: either c for column or r for row\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "            \n",
    "        \"\"\"\n",
    "        if dimension == 'c' and len(vector) == data.shape[0]:\n",
    "            new_vec = vector.reshape(data.shape[0],1)\n",
    "            data = np.append(data, new_vec, axis= 1)\n",
    "        elif dimension == 'r' and len(vector) == data.shape[1]:\n",
    "            new_vec = vector.reshape(1,data.shape[1])\n",
    "            data = np.append(data, new_vec, axis= 0)\n",
    "        else:\n",
    "            raise ValueError('This parameter must be either c for column or r for row')\n",
    "        return data\n",
    "    \n",
    "    def non_vectorized_mask(self, data, threshold):\n",
    "        \"\"\"Element wise array evaluation with loops.\n",
    "        This function takes a multi-dimensional array and then populates a new\n",
    "        multi-dimensional array. If the value in data is below threshold it\n",
    "        will be squared.\n",
    "        Args:\n",
    "            data: multi-dimensional array.\n",
    "            threshold: evaluation value for the array if a value is below it, it is squared\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "        \"\"\"\n",
    "        non_vectorized = np.zeros_like(data, dtype=float)\n",
    "        for row in range(data.shape[0]):\n",
    "            for col in range(data.shape[1]):\n",
    "                val = data[row, col]\n",
    "                if val >= threshold:\n",
    "                    non_vectorized[row, col] = val\n",
    "                    continue\n",
    "                non_vectorized[row, col] = val**2\n",
    "\n",
    "        return non_vectorized\n",
    "\n",
    "    def vectorized_mask(self, data, threshold):\n",
    "        \"\"\"Array evaluation without loops.\n",
    "        This function takes a multi-dimensional array and then populates a new\n",
    "        multi-dimensional array. If the value in data is below threshold it\n",
    "        will be squared. You are required to use a binary mask for this problem\n",
    "        Args:\n",
    "            data: multi-dimensional array.\n",
    "            threshold: evaluation value for the array if a value is below it, it is squared\n",
    "        Returns:\n",
    "            Numpy array of data.\n",
    "        \"\"\"\n",
    "        mask = np.ones((data.shape[0],data.shape[1]))\n",
    "        mask[data < threshold] = 2\n",
    "        data = np.power(data, mask)\n",
    "        return data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34758988139079716\n",
      "0.04879494069539858\n",
      "0.04879494069539858\n",
      "0.04879494069539858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "feature = np.array([[1 ,   0,    0,    0,    1],  \n",
    " [1 ,   0,    1,    1,    1],  \n",
    " [0 ,   1,    0,    0,    1],  \n",
    " [0 ,   1,    1,    0,    0],  \n",
    " [1 ,   1,    0,    1,    1],  \n",
    " [0 ,   1,    0,    1,    0],  \n",
    " [0 ,   0,    1,    1,    1],  \n",
    " [0 ,   0,    1,    0,    0]])\n",
    "\n",
    "def b (q):\n",
    "    # print(q)\n",
    "    if q == 1 or q == 0:\n",
    "        # return - (q * np.log2(q))\n",
    "        return 0\n",
    "    # if q == 0: \n",
    "    #     return - (1-q) * np.log2(1-q)\n",
    "    return - ((q * np.log2(q)) +  (1-q) * np.log2(1-q))\n",
    "\n",
    "ft = pd.DataFrame(feature, columns=['A1', 'A2', 'A3', 'A4', 'Y'])\n",
    "for i in ['A1', 'A2', 'A3', 'A4']:\n",
    "    dp = len(ft[i])\n",
    "    one = len(ft[i][ft[i] > 0 ])\n",
    "    label_res_ppos = Counter(ft['Y'][ft[i] > 0 ])[1]\n",
    "    zeros = dp - one\n",
    "    label_res_npos = Counter(ft['Y'][ft[i] < 1 ])[1]\n",
    "    score = b(5/dp) - (((zeros / dp) * b(label_res_npos / zeros)) +  ((one / dp) * b(label_res_ppos / one)))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A2  A3  A4  Y\n",
       "2   1   0   0  1\n",
       "3   1   1   0  0\n",
       "7   0   1   0  0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = ft[ft['A1'] > 0]\n",
    "zb = ft[ft['A1'] == 0]\n",
    "dd = zb.drop(['A1'], axis=1)\n",
    "dd[dd['A4'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "ft = pb.drop(['A1'], axis=1)\n",
    "for i in ['A2', 'A3', 'A4']:\n",
    "    dp = len(ft[i])\n",
    "    one = len(ft[i][ft[i] > 0 ])\n",
    "    label_res_ppos = Counter(ft['Y'][ft[i] > 0 ])[1]\n",
    "    zeros = dp - one\n",
    "    label_res_npos = Counter(ft['Y'][ft[i] < 1 ])[1]\n",
    "    score = b(3/dp) - (((zeros / dp) * b(label_res_npos / zeros)) +  ((one / dp) * b(label_res_ppos / one)))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b (q):\n",
    "    # print(q)\n",
    "    if q == 1 or q == 0:\n",
    "        # return - (q * np.log2(q))\n",
    "        return 0\n",
    "    if q == 0: \n",
    "        return - (1-q) * np.log2(1-q)\n",
    "    return - ((q * np.log2(q)) +  (1-q) * np.log2(1-q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(9/14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_need = -(5/14 * np.log2(5/14) + 3/8 * np.log2(3/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shit = np.zeros((8,4))\n",
    "label_crap = np.zeros((8,1)) \n",
    "for i in range(feature.shape[0]):\n",
    "    new_shit[i] = feature[i][:-1]\n",
    "    label_crap[i] = feature[i][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiavosh\\AppData\\Local\\Temp\\ipykernel_35820\\1564465926.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest.fit(new_shit, label_crap)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(new_shit, label_crap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4_r = DecisionNode(None, None, None, 1)\n",
    "a4_l = DecisionNode(None, None, None, 0)\n",
    "a4l_r = DecisionNode(None, None, None, 0)\n",
    "a4l_l = DecisionNode(None, None, None, 1)\n",
    "\n",
    "a3_r = DecisionNode(a4_l, a4_r, lambda a4: a4[3] == 0)\n",
    "a3_l = DecisionNode(a4l_l, a4l_r, lambda a4: a4[3] == 0)\n",
    "\n",
    "root_r = DecisionNode(None, None, None, 1)\n",
    "root_l = DecisionNode(a3_l, a3_r, lambda a3: a3[2] == 0)\n",
    "\n",
    "root_a1 = DecisionNode(root_l, root_r, lambda a1: a1[0] == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DecisionNode object at 0x000001F8CA8D0788>\n"
     ]
    }
   ],
   "source": [
    "print(root_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n",
      "----> Right\n",
      "1\n",
      "[1, 0, 1, 1]\n",
      "----> Right\n",
      "1\n",
      "[0, 1, 0, 0]\n",
      "LEFT <----\n",
      "LEFT <----\n",
      "LEFT <----\n",
      "1\n",
      "[0, 1, 1, 0]\n",
      "LEFT <----\n",
      "----> Right\n",
      "LEFT <----\n",
      "0\n",
      "[1, 1, 0, 1]\n",
      "----> Right\n",
      "1\n",
      "[0, 1, 0, 1]\n",
      "LEFT <----\n",
      "LEFT <----\n",
      "----> Right\n",
      "0\n",
      "[0, 0, 1, 1]\n",
      "LEFT <----\n",
      "----> Right\n",
      "----> Right\n",
      "1\n",
      "[0, 0, 1, 0]\n",
      "LEFT <----\n",
      "----> Right\n",
      "LEFT <----\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ht_examples = [[1, 0, 0, 0],\n",
    "            [1, 0, 1, 1],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 1, 1, 0],\n",
    "            [1, 1, 0, 1],\n",
    "            [0, 1, 0, 1],\n",
    "            [0, 0, 1, 1],\n",
    "            [0, 0, 1, 0]]\n",
    "ht_classes = [1, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "\n",
    "for index in range(0, len(ht_examples)):\n",
    "    print(ht_examples[index])\n",
    "    decision = root_a1.decide(ht_examples[index])\n",
    "    print(decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n",
      "1\n",
      "[[[[1, 0]], [[0, 1]]], 1]\n",
      "_____________\n",
      "[1, 0, 1, 1]\n",
      "1\n",
      "[[[[1, 0]], [[0, 1]]], 1]\n",
      "_____________\n",
      "[0, 1, 0, 0]\n",
      "0\n",
      "[[[[1, 0]], [[0, 1]]], 1]\n",
      "1\n",
      "[[[1, 0]], [[0, 1]]]\n",
      "0\n",
      "[[0, 1]]\n",
      "0\n",
      "[0, 1]\n",
      "_____________\n",
      "[0, 1, 1, 0]\n",
      "0\n",
      "[[[[1, 0]], [[0, 1]]], 1]\n",
      "1\n",
      "[[[1, 0]], [[0, 1]]]\n",
      "1\n",
      "[[0, 1]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kiavosh\\Desktop\\School\\Spring 23\\3600\\assignment4_kpeynabard3\\testing_area.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kiavosh/Desktop/School/Spring%2023/3600/assignment4_kpeynabard3/testing_area.ipynb#Y136sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kiavosh/Desktop/School/Spring%2023/3600/assignment4_kpeynabard3/testing_area.ipynb#Y136sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(tree)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kiavosh/Desktop/School/Spring%2023/3600/assignment4_kpeynabard3/testing_area.ipynb#Y136sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     tree \u001b[39m=\u001b[39m tree[i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kiavosh/Desktop/School/Spring%2023/3600/assignment4_kpeynabard3/testing_area.ipynb#Y136sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m_____________\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(ht_examples)):\n",
    "    tree = [\n",
    "        [\n",
    "            [\n",
    "                [1,0]\n",
    "            ],\n",
    "            [\n",
    "                [0,1]\n",
    "            ]\n",
    "        ],\n",
    "        1\n",
    "    ]\n",
    "    print(ht_examples[index])\n",
    "\n",
    "    for i in ht_examples[index]:\n",
    "        if type(tree) == int: \n",
    "            continue\n",
    "        print(i)\n",
    "        print(tree)\n",
    "        tree = tree[i]\n",
    "    print('_____________')\n",
    "    # print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = [\n",
    "    [\n",
    "        [\n",
    "            [1],[0]\n",
    "        ],\n",
    "        [\n",
    "            [0],[1]\n",
    "        ]\n",
    "    ],\n",
    "    1\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = [1, 0, 0, 1, 0, 0, 0]\n",
    "true_label = [1, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "Counter(answer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array(answer)\n",
    "t= np.array(true_label)\n",
    "np.logical_and(a,a+t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((2,2))\n",
    "for i in range(len(true_label)):\n",
    "    if true_label[i] == answer[i]:\n",
    "        matrix[true_label[i]][true_label[i]] += 1\n",
    "    else: \n",
    "        matrix[true_label[i]][answer[i]] += 1\n",
    "        \n",
    "[[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0], [1.0, 3.0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(classifier_output, true_labels):\n",
    "    \"\"\"Create a confusion matrix to measure classifier performance.\n",
    "\n",
    "    Classifier output vs true labels, which is equal to:\n",
    "    Predicted  vs  Actual Values.\n",
    "\n",
    "    Output will in the format:\n",
    "\n",
    "                        |Predicted|\n",
    "    |T|                \n",
    "    |R|    [[true_positive, false_negative],\n",
    "    |U|    [false_positive, true_negative]]\n",
    "    |E|\n",
    "\n",
    "    Args:\n",
    "        classifier_output (list(int)): output from classifier.\n",
    "        true_labels: (list(int): correct classified labels.\n",
    "    Returns:\n",
    "        A two dimensional array representing the confusion matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    matrix = np.zeros((2,2))\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == classifier_output[i]:\n",
    "            matrix[true_labels[i]][true_labels[i]] += 1\n",
    "        else: \n",
    "            matrix[true_labels[i]][classifier_output[i]] += 1\n",
    "            \n",
    "    return [[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]]\n",
    "\n",
    "def test_accuracy_calculation():\n",
    "    \"\"\"Test accuracy calculation.\n",
    "\n",
    "    Asserts:\n",
    "        Accuracy matches for all true labels.\n",
    "    \"\"\"\n",
    "\n",
    "    answer = [0, 0, 0, 0, 0]\n",
    "    true_label = [1, 1, 1, 1, 1]\n",
    "    total_count = len(answer)\n",
    "\n",
    "    for index in range(0, len(answer)):\n",
    "        answer[index] = 1\n",
    "        accuracyc = accuracy(answer, true_label)\n",
    "\n",
    "        print(accuracyc)\n",
    "\n",
    "def accuracy(classifier_output, true_labels):\n",
    "    \"\"\"Get the accuracy of a classifier compared to the correct values.\n",
    "    Accuracy is measured as:\n",
    "        correct_classifications / total_number_examples\n",
    "    Args:\n",
    "        classifier_output (list(int)): output from classifier.\n",
    "        true_labels: (list(int): correct classified labels.\n",
    "    Returns:\n",
    "        The accuracy of the classifier output.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(classifier_output, true_labels)\n",
    "    return (cm[0][0] + cm[1][1]) / len(classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34758988139079716\n",
      "0.04879494069539858\n",
      "0.04879494069539858\n",
      "0.04879494069539858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "feature = np.array([[1 ,   0,    0,    0,    1],  \n",
    " [1 ,   0,    1,    1,    1],  \n",
    " [0 ,   1,    0,    0,    1],  \n",
    " [0 ,   1,    1,    0,    0],  \n",
    " [1 ,   1,    0,    1,    1],  \n",
    " [0 ,   1,    0,    1,    0],  \n",
    " [0 ,   0,    1,    1,    1],  \n",
    " [0 ,   0,    1,    0,    0]])\n",
    "\n",
    "def b (q):\n",
    "    # print(q)\n",
    "    if q == 1 or q == 0:\n",
    "        # return - (q * np.log2(q))\n",
    "        return 0\n",
    "    # if q == 0: \n",
    "    #     return - (1-q) * np.log2(1-q)\n",
    "    return - ((q * np.log2(q)) +  (1-q) * np.log2(1-q))\n",
    "\n",
    "ft = pd.DataFrame(feature, columns=['A1', 'A2', 'A3', 'A4', 'Y'])\n",
    "for i in ['A1', 'A2', 'A3', 'A4']:\n",
    "    dp = len(ft[i])\n",
    "    one = len(ft[i][ft[i] > 0 ])\n",
    "    label_res_ppos = Counter(ft['Y'][ft[i] > 0 ])[1]\n",
    "    zeros = dp - one\n",
    "    label_res_npos = Counter(ft['Y'][ft[i] < 1 ])[1]\n",
    "    score = b(5/dp) - (((zeros / dp) * b(label_res_npos / zeros)) +  ((one / dp) * b(label_res_ppos / one)))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 0 0 0]\n",
      "[0 0 1 1 1 1 0 0]\n",
      "[0 1 0 1 0 0 1 1]\n",
      "[0 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,4):\n",
    "    false_list = feature[feature[:,i] == 0]\n",
    "    true_list = feature[feature[:,i] == 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_list = feature[:,4][feature[:,0] == 0]\n",
    "true_list = feature[:,4][feature[:,0] == 1]\n",
    "false_zo_count = Counter(false_list)\n",
    "true_zo_count = Counter(true_list)\n",
    "leaf_gini_imp_false = 1 - np.power(false_zo_count[0] / len(false_list) , 2) - np.power(false_zo_count[1] / len(false_list) , 2)\n",
    "leaf_gini_imp_true = 1 - np.power(true_zo_count[0] / len(true_list) , 2) - np.power(true_zo_count[1] / len(true_list) , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(class_vector):\n",
    "    \"\"\"Compute the gini impurity for a list of classes.\n",
    "    This is a measure of how often a randomly chosen element\n",
    "    drawn from the class_vector would be incorrectly labeled\n",
    "    if it was randomly labeled according to the distribution\n",
    "    of the labels in the class_vector.\n",
    "    It reaches its minimum at zero when all elements of class_vector\n",
    "    belong to the same class.\n",
    "    Args:\n",
    "        class_vector (list(int)): Vector of classes given as 0 or 1.\n",
    "    Returns:\n",
    "        Floating point number representing the gini impurity.\n",
    "    \"\"\"\n",
    "    if len(class_vector) <= 0:\n",
    "        return 1\n",
    "    false_zo_count = Counter(class_vector)\n",
    "    leaf_gini_imp_false = 1 - np.power(false_zo_count[0] / len(class_vector) , 2) - np.power(false_zo_count[1] / len(class_vector) , 2)\n",
    "    return leaf_gini_imp_false\n",
    "\n",
    "def gini_gain(previous_classes, current_classes):\n",
    "    \"\"\"Compute the gini impurity gain between the previous and current classes.\n",
    "    Args:\n",
    "        previous_classes (list(int)): Vector of classes given as 0 or 1.\n",
    "        current_classes (list(list(int): A list of lists where each list has\n",
    "            0 and 1 values).\n",
    "    Returns:\n",
    "        Floating point number representing the information gain.\n",
    "    \"\"\"\n",
    "    # return (gini_impurity(previous_classes) - np.average([gini_impurity(i) for i in current_classes]))\n",
    "    return (gini_impurity(previous_classes) - np.sum([gini_impurity(i) * len(i) for i in current_classes]) / len(np.hstack(current_classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = gini_gain([1, 1, 1, 0, 0, 0],\n",
    "                        [[1, 1, 1], [0, 0, 0]])\n",
    "\n",
    "# assert .500 == round(gini_gain, 3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = gini_gain([1, 1, 1, 0, 0, 0],[[1, 1, 0], [1, 0, 0]])\n",
    "round(s, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_type = round(gini_gain(\n",
    "            restaurant['restaurants'],\n",
    "            restaurant['split_patrons']), 2)\n",
    "gain_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant = {'restaurants': [0] * 6 + [1] * 6,\n",
    "                           'split_patrons': [[0, 0],\n",
    "                                             [1, 1, 1, 1],\n",
    "                                             [1, 1, 0, 0, 0, 0]],\n",
    "                           'split_food_type': [[0, 1],\n",
    "                                               [0, 1],\n",
    "                                               [0, 0, 1, 1],\n",
    "                                               [0, 0, 1, 1]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant['restaurants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0], [1, 1, 1, 1], [1, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant['split_patrons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.sum([gini_impurity(i) * len(i) for i in restaurant['split_patrons']]) / len(np.hstack(restaurant['split_patrons']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22199999999999998"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5- 0.278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kiavosh\\anaconda3\\envs\\ai_env\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([0, 0]), list([1, 1, 1, 1]), list([1, 1, 0, 0, 0, 0])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(restaurant['split_patrons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(restaurant['split_patrons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(Vectorization.vectorized_glue(None ,data[0], data[1])\n",
    ", columns=['A1', 'A2', 'A3', 'A4', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vectorization.vectorized_glue(None ,data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __build_tree__(features, classes, depth=0):\n",
    "    \"\"\"Build tree that automatically finds the decision functions.\n",
    "    Args:\n",
    "        features (m x n): m examples with n features.\n",
    "        classes (m x 1): Array of Classes.\n",
    "        depth (int): depth to build tree to.\n",
    "    Returns:\n",
    "        Root node of decision tree.\n",
    "    \"\"\"\n",
    "\n",
    "    if depth == 10 :\n",
    "        y = Counter(classes).most_common()[0][0]\n",
    "        return DecisionNode(None, None, None, y)\n",
    "    \n",
    "    if len(set(classes)) == 1 :\n",
    "        y = Counter(classes).most_common()[0][0]\n",
    "        return DecisionNode(None, None, None, y)\n",
    "    \n",
    "    # Finding the best split\n",
    "    ledger = [0,0,0,None,None]\n",
    "    for feature in range(features.shape[1]):\n",
    "        featured_sorted = features[np.argsort(features[:, feature])]\n",
    "        classes_sorted = classes[np.argsort(features[:, feature])]\n",
    "        for dp in range(0, len(features) - 1):\n",
    "            if featured_sorted[dp, feature] != featured_sorted[dp+1, feature]:\n",
    "                curr_gini_info = gini_gain(classes_sorted, [classes_sorted[:dp+1], classes_sorted[dp+1:]])\n",
    "                if curr_gini_info > ledger[0]:\n",
    "                    ledger[0] = curr_gini_info\n",
    "                    ledger[1] = feature\n",
    "                    ledger[2] = dp\n",
    "                    ledger[3] = classes_sorted\n",
    "                    ledger[4] = featured_sorted\n",
    "\n",
    "    if ledger[0] <= 0:\n",
    "        return DecisionNode(None, None, None, y)\n",
    "\n",
    "    curr_features = ledger[4]\n",
    "    curr_classes = ledger[3]\n",
    "\n",
    "    \n",
    "    split_value = curr_features[ledger[2], ledger[1]]\n",
    "    left_leaf = __build_tree__(curr_features[:ledger[2]+1], curr_classes[:ledger[2]+1], depth = depth + 1)\n",
    "    right_leaf = __build_tree__(curr_features[ledger[2]+1:], curr_classes[ledger[2]+1:], depth = depth + 1)\n",
    "\n",
    "    curr_root = DecisionNode(left_leaf, right_leaf, lambda feat: feat[ledger[1]] < split_value)\n",
    "\n",
    "    return curr_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "# Finding the best split\n",
    "sort_tracker = []\n",
    "\n",
    "\n",
    "for feature in range(features.shape[1]):\n",
    "\n",
    "        featured_sorted = features[np.argsort(features[:, feature])]\n",
    "        classes_sorted = classes[np.argsort(features[:, feature])]\n",
    "        sort_tracker.append((featured_sorted, classes_sorted))\n",
    "\n",
    "        thresh = [(gini_gain(classes_sorted, [classes_sorted[:i+1], classes_sorted[i+1:]]), i, feature)\n",
    "                  for i in range(0, len(features) - 1) if featured_sorted[i, feature] != featured_sorted[i+1, feature]]\n",
    "\n",
    "        # split_point = features[find_thresh(featured_sorted[:,i], classes),i]\n",
    "        \n",
    "        # left_sub_y = features[:,i] < split_point\n",
    "        # right_sub_y = features[:,i] > split_point\n",
    "\n",
    "        # gini_list.append((round(gini_gain(classes_sorted, [classes_sorted[left_sub_y], classes_sorted[right_sub_y]]), 10), float(split_point), i))\n",
    "\n",
    "val, split_point, best_alph = list(max(thresh))\n",
    "\n",
    "curr_features = sort_tracker[best_alph][0]\n",
    "curr_classes = sort_tracker[best_alph][1]\n",
    "\n",
    "\n",
    "split_value = curr_features[split_point, best_alph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__build_tree__(data[0], data[1], depth= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = __build_tree__(data[0], data[1], depth= 0)\n",
    "t = [tree.decide(i) for i in data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454810495626822"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([t[i] == data[1][i] for i in range(0,len(t))]).most_common()[0][1]/ len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440233236151603"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([t[i] == data[1][i] for i in range(0,len(t))]).most_common()[0][1]/ len(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454810495626822"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([t[i] == data[1][i] for i in range(0,len(t))]).most_common()[0][1]/ len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT <----\n",
      "LEFT <----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__build_tree__(data[0], data[1], depth= 10).decide([-1.5681, -7.2446,  6.5537, -0.1276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jf(features, classes, depth=0) :\n",
    "    class_count = Counter(classes)\n",
    "    if depth == depth_limit or len(class_count) == 1:\n",
    "        return DecisionNode(None, None, None, class_count.most_common()[0][0])\n",
    "    \n",
    "    #find best feature-threshold combo\n",
    "    best_gain = 0\n",
    "    best_f_idx = -1\n",
    "    best_t_idx = -1\n",
    "    best_sorted_features = None\n",
    "    best_sorted_classes = None\n",
    "    for f_idx in range(features.shape[1]):\n",
    "\n",
    "        #sort dataset by feature values (won't change distribution or count of values, maintains sync)\n",
    "        sorted_idxs = np.argsort(features[:, f_idx])\n",
    "        sorted_features = features[sorted_idxs]\n",
    "        sorted_classes = classes[sorted_idxs]\n",
    "\n",
    "        #check all existing feature values as thresholds\n",
    "        for t_idx in range(features.shape[0] - 1):\n",
    "\n",
    "            #skip duplicate thresholds\n",
    "            if sorted_features[t_idx+1][f_idx] == sorted_features[t_idx][f_idx]:\n",
    "                continue\n",
    "\n",
    "            #find gini gain at current threshold\n",
    "            d1 = sorted_classes[:t_idx+1]\n",
    "            d2 = sorted_classes[t_idx+1:]\n",
    "            curr_gain = gini_gain(sorted_classes, [d1, d2])\n",
    "\n",
    "            #update alpha_best\n",
    "            if curr_gain > best_gain:\n",
    "                best_gain = curr_gain\n",
    "                best_f_idx = f_idx\n",
    "                best_t_idx = t_idx\n",
    "                best_sorted_features = sorted_features\n",
    "                best_sorted_classes = sorted_classes\n",
    "    \n",
    "    #return most likely label as no further information can be gained\n",
    "    if best_gain == 0:\n",
    "        return DecisionNode(None, None, None, class_count.most_common()[0][0])\n",
    "    \n",
    "    #build tree and recurse\n",
    "    threshold = best_sorted_features[best_t_idx][best_f_idx]\n",
    "    left = __build_tree__(best_sorted_features[:best_t_idx+1], best_sorted_classes[:best_t_idx+1], depth+1)\n",
    "    right = __build_tree__(best_sorted_features[best_t_idx+1:], best_sorted_classes[best_t_idx+1:], depth+1)\n",
    "    return DecisionNode(left, right, lambda in_features: in_features[best_f_idx] <= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jt = [jf(data[0], data[1], depth= 10).decide(i) for i in data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([638], dtype=int64),)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data[0]\n",
    "classes = data[1]\n",
    "thresh = [sorted(features[:,0])[i] + sorted(features[:,0])[i+1] / 2 for i in range(0, len(features[:,0]) - 1, 1)]\n",
    "gini_line = []\n",
    "for split_point in thresh:\n",
    "    left_sub_y = features[:,0] < split_point\n",
    "    right_sub_y = features[:,0] > split_point\n",
    "    gini_line.append((round(gini_gain(classes, [classes[left_sub_y], classes[right_sub_y]]), 10), split_point))\n",
    "    \n",
    "np.where(thresh == max(gini_line)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([638], dtype=int64),)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_line = []\n",
    "for split_point in thresh:\n",
    "    left_sub_y = features[:,0] < split_point\n",
    "    right_sub_y = features[:,0] > split_point\n",
    "    gini_line.append((round(gini_gain(classes, [classes[left_sub_y], classes[right_sub_y]]), 10), split_point))\n",
    "\n",
    "np.where(thresh == max(gini_line)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30., 40., 44., ..., 68., 59., 65.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"Class for automatic tree-building and classification.\"\"\"\n",
    "\n",
    "    def __init__(self, depth_limit=float('inf')):\n",
    "        \"\"\"Create a decision tree with a set depth limit.\n",
    "        Starts with an empty root.\n",
    "        Args:\n",
    "            depth_limit (float): The maximum depth to build the tree.\n",
    "        \"\"\"\n",
    "\n",
    "        self.root = None\n",
    "        self.depth_limit = depth_limit\n",
    "\n",
    "    def fit(self, features, classes):\n",
    "        \"\"\"Build the tree from root using __build_tree__().\n",
    "        Args:\n",
    "            features (m x n): m examples with n features.\n",
    "            classes (m x 1): Array of Classes.\n",
    "        \"\"\"\n",
    "\n",
    "        self.root = self.__build_tree__(features, classes)\n",
    "\n",
    "    \n",
    "    def __build_tree__(self, features, classes, depth=0):\n",
    "        \"\"\"Build tree that automatically finds the decision functions.\n",
    "        Args:\n",
    "            features (m x n): m examples with n features.\n",
    "            classes (m x 1): Array of Classes.\n",
    "            depth (int): depth to build tree to.\n",
    "        Returns:\n",
    "            Root node of decision tree.\n",
    "        \"\"\"\n",
    "\n",
    "        if depth == self.depth_limit :\n",
    "            y = Counter(classes).most_common()[0][0]\n",
    "            return DecisionNode(None, None, None, y)\n",
    "    \n",
    "        if len(classes) == 1 :\n",
    "            y = Counter(classes).most_common()[0][0]\n",
    "            return DecisionNode(None, None, None, y)\n",
    "        \n",
    "        # Finding the best split\n",
    "        ledger = [0,0,0,None,None]\n",
    "        for feature in range(features.shape[1]):\n",
    "\n",
    "            featured_sorted = features[np.argsort(features[:, feature])]\n",
    "            classes_sorted = classes[np.argsort(features[:, feature])]\n",
    "\n",
    "            for dp in range(0, len(features) - 1):\n",
    "\n",
    "                curr_gini_info = gini_gain(classes_sorted, [classes_sorted[:dp+1], classes_sorted[dp+1:]])\n",
    "\n",
    "                if curr_gini_info > ledger[0]:\n",
    "                    ledger[0] = curr_gini_info\n",
    "                    ledger[1] = feature\n",
    "                    ledger[2] = dp\n",
    "                    ledger[3] = classes_sorted\n",
    "                    ledger[4] = featured_sorted\n",
    "\n",
    "        if ledger[0] <= 0:\n",
    "            y = Counter(classes).most_common()[0][0]\n",
    "            return DecisionNode(None, None, None, y)\n",
    "\n",
    "        curr_features = ledger[4]\n",
    "        curr_classes = ledger[3]\n",
    "\n",
    "        \n",
    "        split_value = curr_features[ledger[2], ledger[1]]\n",
    "        left_leaf = self.__build_tree__(curr_features[:ledger[2]+1], curr_classes[:ledger[2]+1], depth = depth + 1)\n",
    "        right_leaf = self.__build_tree__(curr_features[ledger[2]+1:], curr_classes[ledger[2]+1:], depth = depth + 1)\n",
    "\n",
    "        curr_root = DecisionNode(left_leaf, right_leaf, lambda feat: feat[ledger[1]] <= split_value)\n",
    "\n",
    "        return curr_root\n",
    "\n",
    "\n",
    "    def classify(self, features):\n",
    "        \"\"\"Use the fitted tree to classify a list of example features.\n",
    "        Args:\n",
    "            features (m x n): m examples with n features.\n",
    "        Return:\n",
    "            A list of class labels.\n",
    "        \"\"\"\n",
    "        class_labels = [self.root.decide(feature) for feature in features]\n",
    "        # class_labels = self.root.decide(feature=features)\n",
    "        return class_labels\n",
    "   \n",
    "\n",
    "class RandomForest:\n",
    "    \"\"\"Random forest classification.\"\"\"\n",
    "\n",
    "    def __init__(self, num_trees, depth_limit, example_subsample_rate,\n",
    "                 attr_subsample_rate):\n",
    "        \"\"\"Create a random forest.\n",
    "         Args:\n",
    "             num_trees (int): fixed number of trees.\n",
    "             depth_limit (int): max depth limit of tree.\n",
    "             example_subsample_rate (float): percentage of example samples.\n",
    "             attr_subsample_rate (float): percentage of attribute samples.\n",
    "        \"\"\"\n",
    "\n",
    "        self.trees = []\n",
    "        self.num_trees = num_trees\n",
    "        self.depth_limit = depth_limit\n",
    "        self.example_subsample_rate = example_subsample_rate\n",
    "        self.attr_subsample_rate = attr_subsample_rate\n",
    "\n",
    "    def fit(self, features, classes):\n",
    "        \"\"\"Build a random forest of decision trees using Bootstrap Aggregation.\n",
    "            features (m x n): m examples with n features.\n",
    "            classes (m x 1): Array of Classes.\n",
    "        \"\"\"\n",
    "        for tree in range(self.num_trees):\n",
    "            dp_sample_indx = np.random.choice(features.shape[0], round(self.example_subsample_rate * features.shape[0]), replace=True)\n",
    "            feature_samples = features[dp_sample_indx]\n",
    "            class_samples = classes[dp_sample_indx]\n",
    "\n",
    "            dt = DecisionTree(depth_limit = self.depth_limit)\n",
    "            dt.fit(feature_samples, class_samples)\n",
    "            self.trees.append(dt)\n",
    "\n",
    "    def classify(self, features):\n",
    "        \"\"\"Classify a list of features based on the trained random forest.\n",
    "        Args:\n",
    "            features (m x n): m examples with n features.\n",
    "        \"\"\"\n",
    "\n",
    "        ballet = np.array([dt.classify(features) for dt in self.trees])\n",
    "        return([Counter(ballet[:,label]).most_common()[0][0] for label in range(features.shape[0])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
